{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import openai \n",
    "from tenacity import * \n",
    "\n",
    "import openai \n",
    "PATH_TO_KEY=\"/home/data1/pie_data_sept_2023/openai_key.txt\"\n",
    "with open(PATH_TO_KEY, 'r') as f:\n",
    "    key = f.read().strip()\n",
    "PATH_TO_ORG=\"/home/data1/pie_data_sept_2023/openai_org.txt\"\n",
    "with open(PATH_TO_ORG, 'r') as f:\n",
    "    org = f.read().strip()\n",
    "openai.organization = org\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def print_model_list(): \n",
    "    response = openai.Model.list()\n",
    "\n",
    "    # Extract and print the model names\n",
    "    for model in response[\"data\"]:\n",
    "        print(model[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dall-e-3\n",
      "whisper-1\n",
      "davinci-002\n",
      "gpt-4-turbo-preview\n",
      "gpt-4-0125-preview\n",
      "babbage-002\n",
      "dall-e-2\n",
      "gpt-3.5-turbo-16k\n",
      "tts-1-hd-1106\n",
      "gpt-4o-2024-05-13\n",
      "tts-1-hd\n",
      "gpt-4o\n",
      "gpt-4\n",
      "gpt-4-0613\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4-1106-preview\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-4-turbo\n",
      "tts-1\n",
      "gpt-3.5-turbo-0301\n",
      "tts-1-1106\n",
      "gpt-3.5-turbo-0125\n",
      "text-embedding-3-large\n",
      "gpt-3.5-turbo\n",
      "text-embedding-3-small\n",
      "gpt-4-32k-0314\n",
      "gpt-3.5-turbo-0613\n",
      "text-embedding-ada-002\n",
      "gpt-4-1106-vision-preview\n",
      "gpt-4-vision-preview\n",
      "gpt-4-0314\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-4o-test-shared\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:model-1:80napqT4\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:pie-opt-debug:80QCzN8Y\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:pie-opt-debug:80QDNscc\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:pie-opt-debug:80QOGZxw\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:pie-opt-debug-3:80QajNrD\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:pie-opt-debug-3:80QqdjXm\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:pie-opt-debug-3:80R17zoQ\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:debug-3:80RO4FUX\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:model-0:80TafmSD\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:syn-0:82QXnoVE\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:syn-1:82m0aOiQ\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:syn-1:82obhzjv\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:model-3:83jfD9Ca\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:syn-50pct-trunc:8LkbGzHZ\n",
      "ft:gpt-3.5-turbo-0613:iclrpieopt:debug-4:8LixfPQY\n"
     ]
    }
   ],
   "source": [
    "print_model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"gpt-4o-2024-05-13\"\n",
    "model = \"gpt-3.5-turbo-0125\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3898, 7)\n"
     ]
    }
   ],
   "source": [
    "# PATH_TO_OUTPUT = \"/data1/shypula/Project_CodeNet/processed\"\n",
    "# if not os.path.exists(PATH_TO_OUTPUT):\n",
    "#     os.makedirs(PATH_TO_OUTPUT)\n",
    "# # save each to a jsonl file, records and lines = True \n",
    "# train_records_df = pd.DataFrame(train_records)\n",
    "# test_records_df = pd.DataFrame(test_records)\n",
    "# val_records_df = pd.DataFrame(val_records)\n",
    "\n",
    "# train_records_df.to_json(os.path.join(PATH_TO_OUTPUT, \"train_descriptions_and_testcases.jsonl\"), lines=True, orient=\"records\")\n",
    "# test_records_df.to_json(os.path.join(PATH_TO_OUTPUT, \"test_descriptions_and_testcases.jsonl\"), lines=True, orient=\"records\")\n",
    "# val_records_df.to_json(os.path.join(PATH_TO_OUTPUT, \"val_descriptions_and_testcases.jsonl\"), lines=True, orient=\"records\")\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "train_records = pd.read_json(\"/home/data1/processed/train_descriptions_and_testcases.jsonl\", lines=True)\n",
    "test_records = pd.read_json(\"/home/data1/processed/test_descriptions_and_testcases.jsonl\", lines=True)\n",
    "val_records = pd.read_json(\"/home/data1/processed/val_descriptions_and_testcases.jsonl\", lines=True)\n",
    "\n",
    "all_records = pd.concat([train_records, test_records, val_records])\n",
    "print(all_records.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score : 600 points\n",
      "Problem Statement\n",
      "Takahashi has N cards. The i-th of these cards has an integer A_i written on it.\n",
      "Takahashi will choose an integer K, and then repeat the following operation some number of times:\n",
      "Choose exactly K cards such that the integers written on them are all different, and eat those cards. (The eaten cards disappear.)\n",
      "For each K = 1,2, \\ldots, N, find the maximum number of times Takahashi can do the operation.\n",
      "Constraints\n",
      " 1 \\le N \\le 3 \\times 10^5 \n",
      " 1 \\le A_i \\le N \n",
      "All values in input are integers.\n",
      "Input\n",
      "Input is given from Standard Input in the following format:\n",
      "N\n",
      "A_1 A_2 \\ldots A_N\n",
      "Output\n",
      "Print N integers.\n",
      "The t-th (1 \\le t \\le N) of them should be the answer for the case K=t.\n",
      "Sample Input 13\n",
      "2 1 2\n",
      "Sample Output 13\n",
      "1\n",
      "0\n",
      "For K = 1, we can do the operation as follows:\n",
      "Choose the first card to eat.\n",
      "Choose the second card to eat.\n",
      "Choose the third card to eat.\n",
      "For K = 2, we can do the operation as follows:\n",
      "Choose the first and second cards to eat.\n",
      "For K = 3, we cannot do the operation at all. Note that we cannot choose the first and third cards at the same time.\n",
      "Sample Input 25\n",
      "1 2 3 4 5\n",
      "Sample Output 25\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "Sample Input 34\n",
      "1 3 3 3\n",
      "Sample Output 34\n",
      "1\n",
      "0\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(all_records[\"description_string\"].iloc[0].replace(\"\\n+\", \"\\n\"))\n",
    "import re \n",
    "canonicalize_newlines = lambda x: re.sub(r\"\\n+\", \"\\n\", x)\n",
    "all_records[\"description_string_canonical\"] = all_records[\"description_string\"].apply(canonicalize_newlines)\n",
    "print(all_records[\"description_string_canonical\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "sys.path.append(\"/home/alex/Documents/PennPhD/program_cal_diverse\") \n",
    "\n",
    "from utils import open_ended "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "results = open_ended.prompt_gpt_to_generate_input_description(\n",
    "    all_records[\"description_string_canonical\"].iloc[0],\n",
    "    open_ended.example_problem, open_ended.example_input, model=open_ended.default_model, temperature=0.5, n=2, top_p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Canonicalized Input Description: \\n\\nAn integer N (1 ≤ N ≤ 3*10^5), representing a quantity or size.\\nA list of integers A of size N, where each integer is between 1 and N. \\n\\n### Example Input:\\n\\n```\\n13\\n2 1 2\\n```\\n\\n### Function Signature:\\nWrite a function f(N, A) that takes in the input. \\ndef f(N: int, A: List[int]): \\n    ''' \\n    N: an integer \\n    A: a list of integers\\n    '''\\n\",\n",
       " \"Canonicalized Input Description: \\n\\nAn integer N (1 ≤ N ≤ 3e5), representing a quantity or size.\\nA list of integers A of size N, where each integer is between 1 and N.\\n\\n### Example Input:\\n\\n```\\n13\\n2 1 2\\n```\\n\\n### Function Signature:\\nWrite a function f(N, A) that takes in the input. \\ndef f(N: int, A: List[int]): \\n    ''' \\n    N: an integer \\n    A: a list of integers\\n    '''\\n\"]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "results = open_ended.prompt_gpt_to_write_testcase_generator(\n",
    "    all_records[\"description_string_canonical\"].iloc[0],\n",
    "    open_ended.example_problem, open_ended.example_tcgen, model=open_ended.default_model, temperature=0.5, n=2, top_p=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here is a test case generator for the given problem statement:\\n\\n```python\\nimport random\\n\\ndef tcgen():\\n    N = random.randint(1, 3 * 10**5)\\n    A = [random.randint(1, N) for _ in range(N)]\\n    \\n    return N, A\\n\\n# Generate test cases\\nfor _ in range(5):\\n    N, A = tcgen()\\n    print(N)\\n    print(\" \".join(map(str, A)))\\n```\\n\\nYou can run this test case generator to generate test cases for the problem statement provided. Each test case will consist of the number of cards, N, and the integers written on each card. You can adjust the number of test cases generated by changing the range in the loop.',\n",
       " 'Here is a test case generator for the given problem statement:\\n\\n```python\\nimport random\\n\\ndef tcgen():\\n    N = random.randint(1, 3 * 10**5)\\n    \\n    A = [random.randint(1, N) for _ in range(N)]\\n    \\n    return N, A\\n\\n# Generate and print a test case\\nN, A = tcgen()\\nprint(N)\\nprint(\" \".join(map(str, A)))\\n```\\n\\nYou can use this test case generator to create random test cases for the problem statement provided. Just call `tcgen()` to generate a new test case with a random number of cards and integer values written on them.']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.open_ended' from '/home/alex/Documents/PennPhD/program_cal_diverse/utils/open_ended.py'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-import \n",
    "import importlib \n",
    "importlib.reload(open_ended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "html_examle = open_ended.make_n_html_from_programs(\n",
    "    all_records[\"description_string_canonical\"].iloc[0],\n",
    "    n=1, \n",
    "    temp=0.0,\n",
    "    top_p=1.0,\n",
    "    model=open_ended.default_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# HTML(html_examle[0][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import tqdm\n",
    "import contextlib\n",
    "import os\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()\n",
    "\n",
    "def process_problems_parallel(problems_with_ids, n, temp, top_p, model, output_directory):\n",
    "    with tqdm_joblib(tqdm.tqdm(total=len(problems_with_ids))) as progress_bar:\n",
    "        results = Parallel(n_jobs=10)(delayed(open_ended.make_n_html_from_programs)(\n",
    "            desc, n, temp, top_p, model, problem_no=problem_id\n",
    "        ) for problem_id, desc in problems_with_ids)\n",
    "        \n",
    "        for (problem_id, _), (html_outputs, input_descriptions, tc_gens, extract_args) in zip(problems_with_ids, results):\n",
    "            problem_output_dir = os.path.join(output_directory, f\"problem_{problem_id}\")\n",
    "            save_outputs_to_files(problem_id, problem_output_dir, html_outputs, input_descriptions, tc_gens, extract_args)\n",
    "            progress_bar.update(1)  # Ensure the progress bar updates correctly per problem processed\n",
    "\n",
    "def save_outputs_to_files(problem_id, output_directory, html_outputs, input_descriptions, tc_gens, extract_args):\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    for i in range(len(html_outputs)):\n",
    "        generation = i + 1\n",
    "        html_file = os.path.join(output_directory, f\"html_{problem_id}_{generation}.html\")\n",
    "        input_desc_file = os.path.join(output_directory, f\"input_desc_{problem_id}_{generation}.txt\")\n",
    "        tc_gen_file = os.path.join(output_directory, f\"tc_gen_{problem_id}_{generation}.txt\")\n",
    "        extract_args_file = os.path.join(output_directory, f\"extract_args_{problem_id}_{generation}.txt\")\n",
    "        \n",
    "        with open(html_file, 'w') as file:\n",
    "            file.write(html_outputs[i])\n",
    "        with open(input_desc_file, 'w') as file:\n",
    "            file.write(input_descriptions[i])\n",
    "        with open(tc_gen_file, 'w') as file:\n",
    "            file.write(tc_gens[i])\n",
    "        with open(extract_args_file, 'w') as file:\n",
    "            file.write(extract_args[i])\n",
    "            \n",
    "\n",
    "\n",
    "# Example usage\n",
    "# problems_with_ids = [('1', 'Some description 1'), ('2', 'Some description 2')]\n",
    "# process_problems_parallel(problems_with_ids, 5, 0.8, 0.9, 'your_model_instance', '/path/to/output')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['description_html', 'description_string', 'input_testcases',\n",
       "       'output_testcases', 'orig_lang_html', 'orig_lang_string',\n",
       "       'codenet_problem_id', 'description_string_canonical'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_records.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [03:41,  1.47s/it]                       \n"
     ]
    }
   ],
   "source": [
    "# re-import \n",
    "import os \n",
    "import importlib \n",
    "import joblib \n",
    "importlib.reload(open_ended)\n",
    "\n",
    "n_examples = 75\n",
    "n_records = all_records.sample(n_examples)\n",
    "descriptions = n_records[\"description_string_canonical\"].tolist()\n",
    "problem_ids = n_records[\"codenet_problem_id\"].tolist()\n",
    "problems_with_ids = list(zip(problem_ids, descriptions))\n",
    "output_dir = \"/home/data1/processed/outputs_v6_4o\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "# process_problems_parallel(problems_with_ids, 3, 0.5, 1.0, open_ended.default_model, output_dir)\n",
    "process_problems_parallel(problems_with_ids, 3, 0.75, 1.0, \"gpt-4o-2024-05-13\", output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_gem5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
